{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5023f39d-fd42-40f7-838e-148d340972af",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Finetune Mask R-CNN with MMDetection\n",
    "\n",
    "This notebook uses the following versions:\n",
    "\n",
    "- `mmcv-full==1.5.0`\n",
    "- `mmdet==2.24.1`\n",
    "- `pycocotools==2.0.4`\n",
    "- `torch==1.11.0`\n",
    "- `torchvision==0.12.0+cu113`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00371771-cfa5-4ec8-8f70-413bd56eb520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'mmdetection'...\n",
      "remote: Enumerating objects: 24460, done.\u001b[K\n",
      "remote: Counting objects: 100% (22/22), done.\u001b[K\n",
      "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
      "remote: Total 24460 (delta 3), reused 11 (delta 2), pack-reused 24438\u001b[K\n",
      "Receiving objects: 100% (24460/24460), 37.56 MiB | 36.18 MiB/s, done.\n",
      "Resolving deltas: 100% (17113/17113), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/open-mmlab/mmdetection.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95709b7-e48e-4933-b3b3-c03d0478846d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 1. Define the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9178f5c-48a3-417b-862c-275f1bb38d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mmdetection/mmdet/datasets/mineapple.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mmdetection/mmdet/datasets/mineapple.py\n",
    "from pathlib import Path\n",
    "\n",
    "import mmcv\n",
    "import numpy as np\n",
    "import torch\n",
    "from mmdet.core.mask.utils import mask2bbox, encode_mask_results\n",
    "from mmdet.datasets.builder import DATASETS\n",
    "from mmdet.datasets.custom import CustomDataset\n",
    "from mmdet.datasets.pipelines import Compose\n",
    "from PIL import Image\n",
    "\n",
    "@DATASETS.register_module()\n",
    "class MineAppleDataset(CustomDataset):\n",
    "    CLASSES = (\"fruit\",)\n",
    "    PALETTE = [(220, 20, 60)]\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_root,\n",
    "        pipeline,\n",
    "        classes=None,\n",
    "        test_mode=False,\n",
    "        filter_empty_gt=True,\n",
    "        file_client_args=dict(backend='disk'),\n",
    "    ):\n",
    "        self.data_root = Path(data_root)\n",
    "        data_dir = self.data_root / \"detection\"\n",
    "        location = \"test\" if test_mode else \"train\"\n",
    "        split_dir = data_dir / location\n",
    "        self.img_prefix = split_dir / \"images\"\n",
    "        self.seg_prefix = split_dir / \"masks\"\n",
    "        self.test_mode = test_mode\n",
    "        self.filter_empty_gt = filter_empty_gt\n",
    "        self.file_client = mmcv.FileClient(**file_client_args)\n",
    "        self.CLASSES = self.get_classes(classes)\n",
    "\n",
    "        # TODO: Not sure what these are or if needed\n",
    "        self.proposal_file = None\n",
    "        self.proposals = None\n",
    "\n",
    "        # Find all images and corresponding masks\n",
    "        image_paths = list(sorted(self.img_prefix.glob(\"*.png\")))\n",
    "        if not image_paths:\n",
    "            raise RuntimeError(\"No images\")\n",
    "        self.data_infos = []\n",
    "        for image_id, image_path in enumerate(image_paths):\n",
    "            width, height = Image.open(image_path).size\n",
    "            data_info = {\n",
    "                # TODO: id needed?\n",
    "                # \"id\": image_id,\n",
    "                \"width\": width,\n",
    "                \"height\": height,\n",
    "                \"filename\": image_path.name,\n",
    "            }\n",
    "            self.data_infos.append(data_info)\n",
    "\n",
    "        # filter images too small and containing no annotations\n",
    "        if not test_mode:\n",
    "            valid_inds = self._filter_imgs()\n",
    "            self.data_infos = [self.data_infos[i] for i in valid_inds]\n",
    "            # set group flag for the sampler\n",
    "            self._set_group_flag()\n",
    "\n",
    "        # processing pipeline\n",
    "        self.pipeline = Compose(pipeline)\n",
    "\n",
    "    def get_ann_info(self, index):\n",
    "        seg_map = self.data_infos[index][\"filename\"]\n",
    "        int_mask = np.array(Image.open(self.seg_prefix / seg_map))\n",
    "\n",
    "        # Convert mask from a 2D image array with objects represented by increasing\n",
    "        # integers to a 3D boolean array\n",
    "        # Source: https://pytorch.org/vision/stable/auto_examples/plot_repurposing_annotations.html\n",
    "        object_ids = np.unique(int_mask)\n",
    "        # Ignore the background object (object_id == 0)\n",
    "        object_ids = object_ids[1:]\n",
    "        masks = int_mask == object_ids[:, None, None]\n",
    "\n",
    "        # Masks to boxes\n",
    "        masks_good = []\n",
    "        boxes = []\n",
    "        for index, mask in enumerate(masks):\n",
    "            y, x = np.where(mask != 0)\n",
    "            box = (np.min(x), np.min(y), np.max(x), np.max(y))\n",
    "            if box[2] <= box[0] or box[3] <= box[1]:\n",
    "                continue\n",
    "            masks_good.append(mask)\n",
    "            boxes.append(box)\n",
    "\n",
    "        # Create the object detection target in its expected format\n",
    "        if boxes:\n",
    "            boxes = np.array(boxes, dtype=np.float32)\n",
    "        else:\n",
    "            boxes = np.zeros((0, 4), dtype=np.float32)\n",
    "        if masks_good:\n",
    "            masks = np.array(masks_good, dtype=np.uint8)\n",
    "        else:\n",
    "            masks = np.zeros((0, *masks.shape[1:]), dtype=np.uint8)\n",
    "        # Assume single label\n",
    "        labels = np.zeros((masks.shape[0],), dtype=np.int64)\n",
    "        # Assume iscrowd is always false\n",
    "        bboxes_ignore = np.zeros((0, 4), dtype=np.float32)\n",
    "        assert boxes.shape[0] == masks.shape[0] == labels.shape[0], (boxes.shape, masks.shape, labels.shape)\n",
    "        assert labels.ndim == 1, labels.ndim\n",
    "        assert bboxes_ignore.shape[0] == 0, bboxes_ignore.shape\n",
    "        assert boxes.shape[1] == bboxes_ignore.shape[1] == 4, (boxes.shape, bboxes_ignore.shape)\n",
    "        assert masks.shape[1:] == (1280, 720), masks.shape\n",
    "        ann = {\n",
    "            \"bboxes\": boxes,\n",
    "            \"labels\": labels,\n",
    "            \"masks\": masks,\n",
    "            \"bboxes_ignore\": bboxes_ignore,\n",
    "            \"seg_map\": seg_map,\n",
    "        }\n",
    "        return ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "973cb156-e857-49b8-ad1b-c4a75b72d202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mmdetection/mmdet/datasets/pipelines/mineapple.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mmdetection/mmdet/datasets/pipelines/mineapple.py\n",
    "from mmdet.core.mask.structures import BitmapMasks\n",
    "from mmdet.datasets.builder import PIPELINES\n",
    "from mmdet.datasets.pipelines.loading import LoadAnnotations\n",
    "\n",
    "\n",
    "@PIPELINES.register_module()\n",
    "class LoadMineappleAnnotations(LoadAnnotations):\n",
    "    def _load_masks(self, results):\n",
    "        h, w = results['img_info']['height'], results['img_info']['width']\n",
    "        gt_masks = results['ann_info']['masks']\n",
    "        # TODO: Maybe I can disable with_masks and do this in the dataset?...\n",
    "        gt_masks = BitmapMasks(gt_masks, h, w)\n",
    "        results['gt_masks'] = gt_masks\n",
    "        results['mask_fields'].append('gt_masks')\n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23a725f-7ea7-4a1d-b1aa-babf3c9fff4b",
   "metadata": {},
   "source": [
    "## Step 2. Fine-tune Mask R-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e2577c3-c80b-4d23-8258-16071a531635",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/ai-playground/object-detection/mmdetection/mmdet/utils/setup_env.py:39: UserWarning: Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\n",
      "  f'Setting OMP_NUM_THREADS environment variable for each process '\n",
      "/home/jupyter/ai-playground/object-detection/mmdetection/mmdet/utils/setup_env.py:49: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\n",
      "  f'Setting MKL_NUM_THREADS environment variable for each process '\n",
      "2022-05-18 10:06:54,701 - mmdet - INFO - Environment info:\n",
      "------------------------------------------------------------\n",
      "sys.platform: linux\n",
      "Python: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) [GCC 9.4.0]\n",
      "CUDA available: True\n",
      "GPU 0: Tesla T4\n",
      "CUDA_HOME: /usr/local/cuda\n",
      "NVCC: Cuda compilation tools, release 11.3, V11.3.109\n",
      "GCC: gcc (Debian 8.3.0-6) 8.3.0\n",
      "PyTorch: 1.11.0\n",
      "PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 7.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2022.0-Product Build 20211112 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.5.2 (Git Hash a9302535553c73243c632ad3c4c80beec3d19a1e)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.3\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37\n",
      "  - CuDNN 8.2\n",
      "  - Magma 2.5.2\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.11.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "TorchVision: 0.12.0+cu113\n",
      "OpenCV: 4.5.5\n",
      "MMCV: 1.5.0\n",
      "MMCV Compiler: GCC 7.3\n",
      "MMCV CUDA Compiler: 11.3\n",
      "MMDetection: 2.24.1+240d7a3\n",
      "------------------------------------------------------------\n",
      "\n",
      "2022-05-18 10:06:55,658 - mmdet - INFO - Distributed training: False\n",
      "2022-05-18 10:06:56,625 - mmdet - INFO - Config:\n",
      "model = dict(\n",
      "    type='MaskRCNN',\n",
      "    backbone=dict(\n",
      "        type='ResNet',\n",
      "        depth=50,\n",
      "        num_stages=4,\n",
      "        out_indices=(0, 1, 2, 3),\n",
      "        frozen_stages=1,\n",
      "        norm_cfg=dict(type='BN', requires_grad=False),\n",
      "        norm_eval=True,\n",
      "        style='caffe',\n",
      "        init_cfg=dict(\n",
      "            type='Pretrained',\n",
      "            checkpoint='open-mmlab://detectron2/resnet50_caffe')),\n",
      "    neck=dict(\n",
      "        type='FPN',\n",
      "        in_channels=[256, 512, 1024, 2048],\n",
      "        out_channels=256,\n",
      "        num_outs=5),\n",
      "    rpn_head=dict(\n",
      "        type='RPNHead',\n",
      "        in_channels=256,\n",
      "        feat_channels=256,\n",
      "        anchor_generator=dict(\n",
      "            type='AnchorGenerator',\n",
      "            scales=[8],\n",
      "            ratios=[0.5, 1.0, 2.0],\n",
      "            strides=[4, 8, 16, 32, 64]),\n",
      "        bbox_coder=dict(\n",
      "            type='DeltaXYWHBBoxCoder',\n",
      "            target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "            target_stds=[1.0, 1.0, 1.0, 1.0]),\n",
      "        loss_cls=dict(\n",
      "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
      "        loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n",
      "    roi_head=dict(\n",
      "        type='StandardRoIHead',\n",
      "        bbox_roi_extractor=dict(\n",
      "            type='SingleRoIExtractor',\n",
      "            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),\n",
      "            out_channels=256,\n",
      "            featmap_strides=[4, 8, 16, 32]),\n",
      "        bbox_head=dict(\n",
      "            type='Shared2FCBBoxHead',\n",
      "            in_channels=256,\n",
      "            fc_out_channels=1024,\n",
      "            roi_feat_size=7,\n",
      "            num_classes=1,\n",
      "            bbox_coder=dict(\n",
      "                type='DeltaXYWHBBoxCoder',\n",
      "                target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "                target_stds=[0.1, 0.1, 0.2, 0.2]),\n",
      "            reg_class_agnostic=False,\n",
      "            loss_cls=dict(\n",
      "                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),\n",
      "            loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n",
      "        mask_roi_extractor=dict(\n",
      "            type='SingleRoIExtractor',\n",
      "            roi_layer=dict(type='RoIAlign', output_size=14, sampling_ratio=0),\n",
      "            out_channels=256,\n",
      "            featmap_strides=[4, 8, 16, 32]),\n",
      "        mask_head=dict(\n",
      "            type='FCNMaskHead',\n",
      "            num_convs=4,\n",
      "            in_channels=256,\n",
      "            conv_out_channels=256,\n",
      "            num_classes=1,\n",
      "            loss_mask=dict(\n",
      "                type='CrossEntropyLoss', use_mask=True, loss_weight=1.0))),\n",
      "    train_cfg=dict(\n",
      "        rpn=dict(\n",
      "            assigner=dict(\n",
      "                type='MaxIoUAssigner',\n",
      "                pos_iou_thr=0.7,\n",
      "                neg_iou_thr=0.3,\n",
      "                min_pos_iou=0.3,\n",
      "                match_low_quality=True,\n",
      "                ignore_iof_thr=-1),\n",
      "            sampler=dict(\n",
      "                type='RandomSampler',\n",
      "                num=256,\n",
      "                pos_fraction=0.5,\n",
      "                neg_pos_ub=-1,\n",
      "                add_gt_as_proposals=False),\n",
      "            allowed_border=-1,\n",
      "            pos_weight=-1,\n",
      "            debug=False),\n",
      "        rpn_proposal=dict(\n",
      "            nms_pre=2000,\n",
      "            max_per_img=1000,\n",
      "            nms=dict(type='nms', iou_threshold=0.7),\n",
      "            min_bbox_size=0),\n",
      "        rcnn=dict(\n",
      "            assigner=dict(\n",
      "                type='MaxIoUAssigner',\n",
      "                pos_iou_thr=0.5,\n",
      "                neg_iou_thr=0.5,\n",
      "                min_pos_iou=0.5,\n",
      "                match_low_quality=True,\n",
      "                ignore_iof_thr=-1),\n",
      "            sampler=dict(\n",
      "                type='RandomSampler',\n",
      "                num=512,\n",
      "                pos_fraction=0.25,\n",
      "                neg_pos_ub=-1,\n",
      "                add_gt_as_proposals=True),\n",
      "            mask_size=28,\n",
      "            pos_weight=-1,\n",
      "            debug=False)),\n",
      "    test_cfg=dict(\n",
      "        rpn=dict(\n",
      "            nms_pre=1000,\n",
      "            max_per_img=1000,\n",
      "            nms=dict(type='nms', iou_threshold=0.7),\n",
      "            min_bbox_size=0),\n",
      "        rcnn=dict(\n",
      "            score_thr=0.05,\n",
      "            nms=dict(type='nms', iou_threshold=0.5),\n",
      "            max_per_img=100,\n",
      "            mask_thr_binary=0.5)))\n",
      "dataset_type = 'CocoDataset'\n",
      "data_root = 'data/coco/'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[103.53, 116.28, 123.675], std=[1.0, 1.0, 1.0], to_rgb=False)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='LoadMineappleAnnotations',\n",
      "        with_bbox=True,\n",
      "        with_mask=True,\n",
      "        poly2mask=False),\n",
      "    dict(\n",
      "        type='Resize',\n",
      "        img_scale=[(1333, 640), (1333, 672), (1333, 704), (1333, 736),\n",
      "                   (1333, 768), (1333, 800)],\n",
      "        multiscale_mode='value',\n",
      "        keep_ratio=True),\n",
      "    dict(type='RandomFlip', flip_ratio=0.5),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[103.53, 116.28, 123.675],\n",
      "        std=[1.0, 1.0, 1.0],\n",
      "        to_rgb=False),\n",
      "    dict(type='Pad', size_divisor=32),\n",
      "    dict(type='DefaultFormatBundle'),\n",
      "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='MultiScaleFlipAug',\n",
      "        img_scale=(1333, 800),\n",
      "        flip=False,\n",
      "        transforms=[\n",
      "            dict(type='Resize', keep_ratio=True),\n",
      "            dict(type='RandomFlip'),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[103.53, 116.28, 123.675],\n",
      "                std=[1.0, 1.0, 1.0],\n",
      "                to_rgb=False),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='Collect', keys=['img'])\n",
      "        ])\n",
      "]\n",
      "data = dict(\n",
      "    samples_per_gpu=2,\n",
      "    workers_per_gpu=2,\n",
      "    train=dict(\n",
      "        type='MineAppleDataset',\n",
      "        classes=('fruit', ),\n",
      "        data_root='../data/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='LoadMineappleAnnotations',\n",
      "                with_bbox=True,\n",
      "                with_mask=True,\n",
      "                poly2mask=False),\n",
      "            dict(\n",
      "                type='Resize',\n",
      "                img_scale=[(1333, 640), (1333, 672), (1333, 704), (1333, 736),\n",
      "                           (1333, 768), (1333, 800)],\n",
      "                multiscale_mode='value',\n",
      "                keep_ratio=True),\n",
      "            dict(type='RandomFlip', flip_ratio=0.5),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[103.53, 116.28, 123.675],\n",
      "                std=[1.0, 1.0, 1.0],\n",
      "                to_rgb=False),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='DefaultFormatBundle'),\n",
      "            dict(\n",
      "                type='Collect',\n",
      "                keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks'])\n",
      "        ]),\n",
      "    val=dict(\n",
      "        type='MineAppleDataset',\n",
      "        classes=('fruit', ),\n",
      "        data_root='../data/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(1333, 800),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[103.53, 116.28, 123.675],\n",
      "                        std=[1.0, 1.0, 1.0],\n",
      "                        to_rgb=False),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ]),\n",
      "    test=dict(\n",
      "        type='MineAppleDataset',\n",
      "        classes=('fruit', ),\n",
      "        data_root='../data/',\n",
      "        test_mode=True,\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(1333, 800),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[103.53, 116.28, 123.675],\n",
      "                        std=[1.0, 1.0, 1.0],\n",
      "                        to_rgb=False),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ]))\n",
      "evaluation = dict(metric=['bbox', 'segm'])\n",
      "optimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0001)\n",
      "optimizer_config = dict(grad_clip=None)\n",
      "lr_config = dict(\n",
      "    policy='step',\n",
      "    warmup='linear',\n",
      "    warmup_iters=500,\n",
      "    warmup_ratio=0.001,\n",
      "    step=[7])\n",
      "runner = dict(type='EpochBasedRunner', max_epochs=1)\n",
      "checkpoint_config = dict(interval=1)\n",
      "log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])\n",
      "custom_hooks = [dict(type='NumClassCheckHook')]\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = 'https://download.openmmlab.com/mmdetection/v2.0/mask_rcnn/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco_bbox_mAP-0.408__segm_mAP-0.37_20200504_163245-42aa3d00.pth'\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "opencv_num_threads = 0\n",
      "mp_start_method = 'fork'\n",
      "auto_scale_lr = dict(enable=False, base_batch_size=16)\n",
      "custom_imports = dict(\n",
      "    imports=['mmdet.datasets.mineapple', 'mmdet.datasets.pipelines.mineapple'],\n",
      "    allow_failed_imports=False)\n",
      "classes = ('fruit', )\n",
      "num_classes = 1\n",
      "dataset = dict(\n",
      "    _delete_=True,\n",
      "    type='MineAppleDataset',\n",
      "    classes=('fruit', ),\n",
      "    data_root='../data/')\n",
      "work_dir = './work_dirs/fruit_detection'\n",
      "auto_resume = False\n",
      "gpu_ids = [0]\n",
      "\n",
      "2022-05-18 10:06:56,626 - mmdet - INFO - Set random seed to 1142494668, deterministic: False\n",
      "2022-05-18 10:06:57,007 - mmdet - INFO - initialize ResNet with init_cfg {'type': 'Pretrained', 'checkpoint': 'open-mmlab://detectron2/resnet50_caffe'}\n",
      "2022-05-18 10:06:57,007 - mmcv - INFO - load model from: open-mmlab://detectron2/resnet50_caffe\n",
      "2022-05-18 10:06:57,008 - mmcv - INFO - load checkpoint from openmmlab path: open-mmlab://detectron2/resnet50_caffe\n",
      "2022-05-18 10:06:57,081 - mmcv - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: conv1.bias\n",
      "\n",
      "2022-05-18 10:06:57,100 - mmdet - INFO - initialize FPN with init_cfg {'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}\n",
      "2022-05-18 10:06:57,126 - mmdet - INFO - initialize RPNHead with init_cfg {'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01}\n",
      "2022-05-18 10:06:57,132 - mmdet - INFO - initialize Shared2FCBBoxHead with init_cfg [{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'distribution': 'uniform', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]\n",
      "/home/jupyter/ai-playground/object-detection/mmdetection/mmdet/datasets/custom.py:180: UserWarning: CustomDataset does not support filtering empty gt images.\n",
      "  'CustomDataset does not support filtering empty gt images.')\n",
      "2022-05-18 10:07:00,588 - mmdet - INFO - Automatic scaling of learning rate (LR) has been disabled.\n",
      "2022-05-18 10:07:00,625 - mmdet - INFO - load checkpoint from http path: https://download.openmmlab.com/mmdetection/v2.0/mask_rcnn/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco_bbox_mAP-0.408__segm_mAP-0.37_20200504_163245-42aa3d00.pth\n",
      "2022-05-18 10:07:00,779 - mmdet - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for roi_head.bbox_head.fc_cls.weight: copying a param with shape torch.Size([81, 1024]) from checkpoint, the shape in current model is torch.Size([2, 1024]).\n",
      "size mismatch for roi_head.bbox_head.fc_cls.bias: copying a param with shape torch.Size([81]) from checkpoint, the shape in current model is torch.Size([2]).\n",
      "size mismatch for roi_head.bbox_head.fc_reg.weight: copying a param with shape torch.Size([320, 1024]) from checkpoint, the shape in current model is torch.Size([4, 1024]).\n",
      "size mismatch for roi_head.bbox_head.fc_reg.bias: copying a param with shape torch.Size([320]) from checkpoint, the shape in current model is torch.Size([4]).\n",
      "size mismatch for roi_head.mask_head.conv_logits.weight: copying a param with shape torch.Size([80, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([1, 256, 1, 1]).\n",
      "size mismatch for roi_head.mask_head.conv_logits.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([1]).\n",
      "2022-05-18 10:07:00,783 - mmdet - INFO - Start running, host: jupyter@dev, work_dir: /home/jupyter/ai-playground/object-detection/mmdetection/work_dirs/fruit_detection\n",
      "2022-05-18 10:07:00,783 - mmdet - INFO - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) NumClassCheckHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(ABOVE_NORMAL) OptimizerHook                      \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) NumClassCheckHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_run:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "2022-05-18 10:07:00,784 - mmdet - INFO - workflow: [('train', 1)], max: 1 epochs\n",
      "2022-05-18 10:07:00,784 - mmdet - INFO - Checkpoints will be saved to /home/jupyter/ai-playground/object-detection/mmdetection/work_dirs/fruit_detection by HardDiskBackend.\n",
      "2022-05-18 10:07:42,180 - mmdet - INFO - Epoch [1][50/335]\tlr: 9.890e-04, eta: 0:03:54, time: 0.822, data_time: 0.212, memory: 3910, loss_rpn_cls: 0.1525, loss_rpn_bbox: 0.1529, loss_cls: 0.4805, acc: 78.7930, loss_bbox: 0.6460, loss_mask: 0.9977, loss: 2.4297\n",
      "2022-05-18 10:08:19,690 - mmdet - INFO - Epoch [1][100/335]\tlr: 1.988e-03, eta: 0:03:04, time: 0.750, data_time: 0.155, memory: 3910, loss_rpn_cls: 0.0662, loss_rpn_bbox: 0.1630, loss_cls: 0.3681, acc: 83.1289, loss_bbox: 0.5703, loss_mask: 0.3611, loss: 1.5286\n",
      "2022-05-18 10:08:57,061 - mmdet - INFO - Epoch [1][150/335]\tlr: 2.987e-03, eta: 0:02:23, time: 0.747, data_time: 0.151, memory: 3910, loss_rpn_cls: 0.0601, loss_rpn_bbox: 0.1567, loss_cls: 0.3307, acc: 85.0176, loss_bbox: 0.5108, loss_mask: 0.3536, loss: 1.4120\n",
      "2022-05-18 10:09:34,715 - mmdet - INFO - Epoch [1][200/335]\tlr: 3.986e-03, eta: 0:01:43, time: 0.754, data_time: 0.167, memory: 3910, loss_rpn_cls: 0.0560, loss_rpn_bbox: 0.1604, loss_cls: 0.3128, acc: 86.0508, loss_bbox: 0.4817, loss_mask: 0.3400, loss: 1.3509\n",
      "2022-05-18 10:10:12,374 - mmdet - INFO - Epoch [1][250/335]\tlr: 4.985e-03, eta: 0:01:05, time: 0.754, data_time: 0.161, memory: 3910, loss_rpn_cls: 0.0466, loss_rpn_bbox: 0.1615, loss_cls: 0.3027, acc: 86.2891, loss_bbox: 0.4991, loss_mask: 0.3534, loss: 1.3633\n",
      "2022-05-18 10:10:50,012 - mmdet - INFO - Epoch [1][300/335]\tlr: 5.984e-03, eta: 0:00:26, time: 0.752, data_time: 0.163, memory: 3910, loss_rpn_cls: 0.0624, loss_rpn_bbox: 0.1823, loss_cls: 0.3223, acc: 85.8438, loss_bbox: 0.4876, loss_mask: 0.3446, loss: 1.3993\n",
      "2022-05-18 10:11:15,806 - mmdet - INFO - Saving checkpoint at 1 epochs\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 331/331, 2.1 task/s, elapsed: 154s, ETA:     0sTraceback (most recent call last):\n",
      "  File \"tools/train.py\", line 237, in <module>\n",
      "    main()\n",
      "  File \"tools/train.py\", line 233, in main\n",
      "    meta=meta)\n",
      "  File \"/home/jupyter/ai-playground/object-detection/mmdetection/mmdet/apis/train.py\", line 244, in train_detector\n",
      "    runner.run(data_loaders, cfg.workflow)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/mmcv/runner/epoch_based_runner.py\", line 127, in run\n",
      "    epoch_runner(data_loaders[i], **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/mmcv/runner/epoch_based_runner.py\", line 54, in train\n",
      "    self.call_hook('after_train_epoch')\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/mmcv/runner/base_runner.py\", line 309, in call_hook\n",
      "    getattr(hook, fn_name)(self)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/mmcv/runner/hooks/evaluation.py\", line 267, in after_train_epoch\n",
      "    self._do_evaluate(runner)\n",
      "  File \"/home/jupyter/ai-playground/object-detection/mmdetection/mmdet/core/evaluation/eval_hooks.py\", line 58, in _do_evaluate\n",
      "    key_score = self.evaluate(runner, results)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/mmcv/runner/hooks/evaluation.py\", line 364, in evaluate\n",
      "    results, logger=runner.logger, **self.eval_kwargs)\n",
      "  File \"/home/jupyter/ai-playground/object-detection/mmdetection/mmdet/datasets/custom.py\", line 333, in evaluate\n",
      "    assert len(metric) == 1\n",
      "AssertionError\n"
     ]
    }
   ],
   "source": [
    "!cd mmdetection && PYTHONPATH=. python tools/train.py ../fruit_detection.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04d0e20-dbd0-464b-abb7-dc5ad2f83452",
   "metadata": {},
   "source": [
    "## Rough: Train in code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6a218ffa-e346-4743-9e6f-bce07c070f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmcv import Config\n",
    "from mmdet.datasets import build_dataset, build_dataloader\n",
    "from mmdet.models import build_detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "87303267-c8f0-4f39-a2a5-eec22ea8c126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/jupyter/ai-playground/object-detection',\n",
       " '/opt/conda/lib/python37.zip',\n",
       " '/opt/conda/lib/python3.7',\n",
       " '/opt/conda/lib/python3.7/lib-dynload',\n",
       " '',\n",
       " '/opt/conda/lib/python3.7/site-packages',\n",
       " '/opt/conda/lib/python3.7/site-packages/IPython/extensions',\n",
       " '/home/jupyter/.ipython',\n",
       " 'mmdetection']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "if \"mmdetection\" not in sys.path:\n",
    "    sys.path.append(\"mmdetection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e2ab08ff-275c-4c01-a475-8c8bfc972bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = \"fruit_detection.py\"\n",
    "\n",
    "cfg = Config.fromfile(config)\n",
    "\n",
    "args = cfg.data.train.copy()\n",
    "args.pop(\"type\")\n",
    "dataset = MineAppleDataset(**args)\n",
    "# datasets = [build_dataset(cfg.data.train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "049bec5c-1007-4fc1-bc32-8e14dc5a6255",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_detector(cfg.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2c2c842-d879-4076-bdfa-90f011a9d011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single GPU training\n",
    "cfg.gpu_ids = range(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e2c0671-c504-49d9-8efd-9a43935e41b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.distributed as dist\n",
    "from mmdet.apis import init_random_seed, set_random_seed, train_detector\n",
    "from mmdet.utils import (collect_env, get_device, get_root_logger,\n",
    "                         setup_multi_processes, update_data_root)\n",
    "\n",
    "deterministic = False\n",
    "seed = 0\n",
    "\n",
    "cfg.device = get_device()\n",
    "\n",
    "# set random seeds\n",
    "seed = init_random_seed(seed, device=cfg.device)\n",
    "set_random_seed(seed, deterministic=deterministic)\n",
    "cfg.seed = seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bf5acb9-8e21-4f96-b517-084879737ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "distributed = False\n",
    "runner_type = 'EpochBasedRunner' if 'runner' not in cfg else cfg.runner['type']\n",
    "train_dataloader_default_args = dict(\n",
    "    samples_per_gpu=2,\n",
    "    workers_per_gpu=2,\n",
    "    # `num_gpus` will be ignored if distributed\n",
    "    num_gpus=len(cfg[\"gpu_ids\"]),\n",
    "    dist=distributed,\n",
    "    seed=cfg[\"seed\"],\n",
    "    runner_type=runner_type,\n",
    "    persistent_workers=False)\n",
    "\n",
    "train_loader_cfg = {\n",
    "    **train_dataloader_default_args,\n",
    "    **cfg.data.get('train_dataloader', {})\n",
    "}\n",
    "data_loader = build_dataloader(dataset, **train_loader_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5215f7a3-911b-4526-89b7-bf01f96e1cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "from mmdet.apis.train import train_detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d3ceb65-89b4-40c7-8271-a9a70eead709",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_validate = False\n",
    "\n",
    "timestamp = time.strftime('%Y%m%d_%H%M%S', time.localtime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "272b290a-c853-4e3d-80e2-60396e0013e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.work_dir = os.path.join('./work_dirs',\n",
    "                        os.path.splitext(os.path.basename(config))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686a145a-cb7e-45f4-ba69-af03152dc5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_info_dict = collect_env()\n",
    "env_info = '\\n'.join([(f'{k}: {v}') for k, v in env_info_dict.items()])\n",
    "meta = {\n",
    "    \"env_info\": env_info,\n",
    "    \"config\": cfg.pretty_text,\n",
    "    \"seed\": cfg.seed,\n",
    "    \"exp_name\": os.path.basename(config)\n",
    "}\n",
    "\n",
    "train_detector(model, [dataset], cfg, distributed=distributed, validate=(not no_validate), timestamp=timestamp, meta=meta)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-11.m91",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-11:m91"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
