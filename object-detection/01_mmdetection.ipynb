{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5023f39d-fd42-40f7-838e-148d340972af",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Finetune Mask R-CNN with MMDetection\n",
    "\n",
    "This notebook uses the following versions:\n",
    "\n",
    "- `mmcv-full==1.5.0`\n",
    "- `mmdet==2.24.1`\n",
    "- `pycocotools==2.0.4`\n",
    "- `torch==1.11.0`\n",
    "- `torchvision==0.12.0+cu113`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00371771-cfa5-4ec8-8f70-413bd56eb520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'mmdetection'...\n",
      "remote: Enumerating objects: 24460, done.\u001b[K\n",
      "remote: Counting objects: 100% (22/22), done.\u001b[K\n",
      "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
      "remote: Total 24460 (delta 3), reused 11 (delta 2), pack-reused 24438\u001b[K\n",
      "Receiving objects: 100% (24460/24460), 37.56 MiB | 36.18 MiB/s, done.\n",
      "Resolving deltas: 100% (17113/17113), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/open-mmlab/mmdetection.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95709b7-e48e-4933-b3b3-c03d0478846d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 1. Define the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9178f5c-48a3-417b-862c-275f1bb38d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mmdetection/mmdet/datasets/mineapple.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mmdetection/mmdet/datasets/mineapple.py\n",
    "from pathlib import Path\n",
    "\n",
    "import mmcv\n",
    "import numpy as np\n",
    "import torch\n",
    "from mmdet.core.mask.utils import mask2bbox, encode_mask_results\n",
    "from mmdet.datasets.builder import DATASETS\n",
    "from mmdet.datasets.coco import CocoDataset\n",
    "from mmdet.datasets.pipelines import Compose\n",
    "from PIL import Image\n",
    "\n",
    "@DATASETS.register_module()\n",
    "class MineAppleDataset(CocoDataset):\n",
    "    CLASSES = (\"fruit\",)\n",
    "    PALETTE = [(220, 20, 60)]\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_root,\n",
    "        pipeline,\n",
    "        classes=None,\n",
    "        test_mode=False,\n",
    "        filter_empty_gt=True,\n",
    "        file_client_args=dict(backend='disk'),\n",
    "    ):\n",
    "        self.data_root = Path(data_root)\n",
    "        data_dir = self.data_root / \"detection\"\n",
    "        location = \"test\" if test_mode else \"train\"\n",
    "        split_dir = data_dir / location\n",
    "        self.img_prefix = split_dir / \"images\"\n",
    "        self.seg_prefix = split_dir / \"masks\"\n",
    "        self.test_mode = test_mode\n",
    "        self.filter_empty_gt = filter_empty_gt\n",
    "        self.file_client = mmcv.FileClient(**file_client_args)\n",
    "        self.CLASSES = self.get_classes(classes)\n",
    "\n",
    "        # TODO: Not sure what these are or if needed\n",
    "        self.proposal_file = None\n",
    "        self.proposals = None\n",
    "\n",
    "        # Find all images and corresponding masks\n",
    "        image_paths = list(sorted(self.img_prefix.glob(\"*.png\")))\n",
    "        if not image_paths:\n",
    "            raise RuntimeError(\"No images\")\n",
    "        self.data_infos = []\n",
    "        for image_id, image_path in enumerate(image_paths):\n",
    "            width, height = Image.open(image_path).size\n",
    "            data_info = {\n",
    "                # TODO: id needed?\n",
    "                # \"id\": image_id,\n",
    "                \"width\": width,\n",
    "                \"height\": height,\n",
    "                \"filename\": image_path.name,\n",
    "            }\n",
    "            self.data_infos.append(data_info)\n",
    "\n",
    "        # filter images too small and containing no annotations\n",
    "        if not test_mode:\n",
    "            # valid_inds = self._filter_imgs()\n",
    "            # self.data_infos = [self.data_infos[i] for i in valid_inds]\n",
    "            # set group flag for the sampler\n",
    "            self._set_group_flag()\n",
    "\n",
    "        # processing pipeline\n",
    "        self.pipeline = Compose(pipeline)\n",
    "\n",
    "    def get_ann_info(self, index):\n",
    "        seg_map = self.data_infos[index][\"filename\"]\n",
    "        int_mask = np.array(Image.open(self.seg_prefix / seg_map))\n",
    "\n",
    "        # Convert mask from a 2D image array with objects represented by increasing\n",
    "        # integers to a 3D boolean array\n",
    "        # Source: https://pytorch.org/vision/stable/auto_examples/plot_repurposing_annotations.html\n",
    "        object_ids = np.unique(int_mask)\n",
    "        # Ignore the background object (object_id == 0)\n",
    "        object_ids = object_ids[1:]\n",
    "        masks = int_mask == object_ids[:, None, None]\n",
    "\n",
    "        # Masks to boxes\n",
    "        masks_good = []\n",
    "        boxes = []\n",
    "        for index, mask in enumerate(masks):\n",
    "            y, x = np.where(mask != 0)\n",
    "            box = (np.min(x), np.min(y), np.max(x), np.max(y))\n",
    "            if box[2] <= box[0] or box[3] <= box[1]:\n",
    "                continue\n",
    "            masks_good.append(mask)\n",
    "            boxes.append(box)\n",
    "\n",
    "        # Create the object detection target in its expected format\n",
    "        if boxes:\n",
    "            boxes = np.array(boxes, dtype=np.float32)\n",
    "        else:\n",
    "            boxes = np.zeros((0, 4), dtype=np.float32)\n",
    "        if masks_good:\n",
    "            masks = np.array(masks_good, dtype=np.uint8)\n",
    "        else:\n",
    "            masks = np.zeros((0, *masks.shape[1:]), dtype=np.uint8)\n",
    "        # Assume single label\n",
    "        labels = np.zeros((masks.shape[0],), dtype=np.int64)\n",
    "        # Assume iscrowd is always false\n",
    "        bboxes_ignore = np.zeros((0, 4), dtype=np.float32)\n",
    "        assert boxes.shape[0] == masks.shape[0] == labels.shape[0], (boxes.shape, masks.shape, labels.shape)\n",
    "        assert labels.ndim == 1, labels.ndim\n",
    "        assert bboxes_ignore.shape[0] == 0, bboxes_ignore.shape\n",
    "        assert boxes.shape[1] == bboxes_ignore.shape[1] == 4, (boxes.shape, bboxes_ignore.shape)\n",
    "        assert masks.shape[1:] == (1280, 720), masks.shape\n",
    "        ann = {\n",
    "            \"bboxes\": boxes,\n",
    "            \"labels\": labels,\n",
    "            \"masks\": masks,\n",
    "            \"bboxes_ignore\": bboxes_ignore,\n",
    "            \"seg_map\": seg_map,\n",
    "        }\n",
    "        return ann\n",
    "\n",
    "    # def _filter_imgs(self, **kwargs):\n",
    "    #     # Assume all images are valid\n",
    "    #     self.img_ids = list(range(len(self.data_infos)))\n",
    "    #     return self.img_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "973cb156-e857-49b8-ad1b-c4a75b72d202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mmdetection/mmdet/datasets/pipelines/mineapple.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mmdetection/mmdet/datasets/pipelines/mineapple.py\n",
    "from mmdet.core.mask.structures import BitmapMasks\n",
    "from mmdet.datasets.builder import PIPELINES\n",
    "from mmdet.datasets.pipelines.loading import LoadAnnotations\n",
    "\n",
    "\n",
    "@PIPELINES.register_module()\n",
    "class LoadMineappleAnnotations(LoadAnnotations):\n",
    "    def _load_masks(self, results):\n",
    "        h, w = results['img_info']['height'], results['img_info']['width']\n",
    "        gt_masks = results['ann_info']['masks']\n",
    "        # TODO: Maybe I can disable with_masks and do this in the dataset?...\n",
    "        gt_masks = BitmapMasks(gt_masks, h, w)\n",
    "        results['gt_masks'] = gt_masks\n",
    "        results['mask_fields'].append('gt_masks')\n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23a725f-7ea7-4a1d-b1aa-babf3c9fff4b",
   "metadata": {},
   "source": [
    "## Step 2. Fine-tune Mask R-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2577c3-c80b-4d23-8258-16071a531635",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setting PYTHONPATH to make custom_imports in the config work.\n",
    "# Not sure if there's a better way.\n",
    "!PYTHONPATH=mmdetection python mmdetection/tools/train.py fruit_detection.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e340d63-0721-4e47-8176-cf473ec1c637",
   "metadata": {},
   "source": [
    "## Make COCO API from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5ddf9f73-4941-493b-a395-4236ca03ac3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"mmdetection\" not in sys.path:\n",
    "    sys.path.insert(0, \"mmdetection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b2db48ef-55ec-4bde-8d05-2760dec289ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = \"fruit_detection.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0d1edb23-35ef-4d0d-8d5b-a2e7b6904f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmcv import Config\n",
    "from mmdet.datasets import build_dataset, build_dataloader\n",
    "from mmdet.models import build_detector\n",
    "\n",
    "cfg = Config.fromfile(config)\n",
    "dataset = build_dataset(cfg.data.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6e581d42-2e22-4ae9-9432-5a628ac6a873",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d2dedefa-1735-499b-a2f6-344d8f158693",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdet.datasets.api_wrappers.coco_api import COCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2bce1125-bbec-4ecb-b60b-3698e06f8fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "coco = COCO()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "266460bd-99a2-4652-ab9c-33ab55b680c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "54e33484-b6c9-4ca6-b336-82d1bfbb7997",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_info = ds.get_ann_info(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "fd93e572-1f0d-44de-b2fa-9303af9f1375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['bboxes', 'labels', 'masks', 'bboxes_ignore', 'seg_map'])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_info.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4b2f1818-c20f-4f27-ae77-b61c14920f11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95, 720, 1280)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_info['masks'].transpose(0, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "de40c75e-6881-4c92-aced-a29b62d81ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from mmdet.utils import get_device\n",
    "\n",
    "device = get_device()\n",
    "\n",
    "# annotation IDs need to start at 1, not 0, see torchvision issue #1530\n",
    "ann_id = 1\n",
    "dataset = {\"images\": [], \"categories\": [], \"annotations\": []}\n",
    "categories = set()\n",
    "for img_idx in range(len(ds)):\n",
    "    data_info = ds.data_infos[img_idx]\n",
    "    img_dict = {}\n",
    "    img_dict[\"id\"] = img_idx\n",
    "    img_dict[\"height\"] = data_info[\"height\"]\n",
    "    img_dict[\"width\"] = data_info[\"height\"]\n",
    "    dataset[\"images\"].append(img_dict)\n",
    "\n",
    "    ann_info = ds.get_ann_info(img_idx)\n",
    "    labels = ann_info[\"labels\"].tolist()\n",
    "    bboxes = ann_info[\"bboxes\"].copy()\n",
    "    bboxes[:, 2:] -= bboxes[:, :2]\n",
    "    areas = bboxes[:, 2:].prod(axis=-1)\n",
    "    bboxes = bboxes.tolist()\n",
    "    iscrowd = [0] * len(labels)\n",
    "    if \"masks\" in targets:\n",
    "        masks = targets[\"masks\"]\n",
    "        # make masks Fortran contiguous for coco_mask\n",
    "        masks = np.asfortranarray(masks)\n",
    "    # TODO: Continue here\n",
    "    num_objs = len(bboxes)\n",
    "    for i in range(num_objs):\n",
    "        ann = {}\n",
    "        ann[\"image_id\"] = image_id\n",
    "        ann[\"bbox\"] = bboxes[i]\n",
    "        ann[\"category_id\"] = labels[i]\n",
    "        categories.add(labels[i])\n",
    "        ann[\"area\"] = areas[i]\n",
    "        ann[\"iscrowd\"] = iscrowd[i]\n",
    "        ann[\"id\"] = ann_id\n",
    "        if \"masks\" in targets:\n",
    "            ann[\"segmentation\"] = coco_mask.encode(masks[i].numpy())\n",
    "        if \"keypoints\" in targets:\n",
    "            ann[\"keypoints\"] = keypoints[i]\n",
    "            ann[\"num_keypoints\"] = sum(k != 0 for k in keypoints[i][2::3])\n",
    "        dataset[\"annotations\"].append(ann)\n",
    "        ann_id += 1\n",
    "dataset[\"categories\"] = [{\"id\": i} for i in sorted(categories)]\n",
    "coco.dataset = dataset\n",
    "coco.createIndex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae4109f-fbb2-4bc7-a92c-d7deb0cecbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_coco_api(ds):\n",
    "    coco_ds = COCO()\n",
    "    # annotation IDs need to start at 1, not 0, see torchvision issue #1530\n",
    "    ann_id = 1\n",
    "    dataset = {\"images\": [], \"categories\": [], \"annotations\": []}\n",
    "    categories = set()\n",
    "    for img_idx in range(len(ds)):\n",
    "        # find better way to get target\n",
    "        # targets = ds.get_annotations(img_idx)\n",
    "        img, targets = ds[img_idx]\n",
    "        image_id = targets[\"image_id\"].item()\n",
    "        img_dict = {}\n",
    "        img_dict[\"id\"] = image_id\n",
    "        img_dict[\"height\"] = img.shape[-2]\n",
    "        img_dict[\"width\"] = img.shape[-1]\n",
    "        dataset[\"images\"].append(img_dict)\n",
    "        bboxes = targets[\"boxes\"].clone()\n",
    "        bboxes[:, 2:] -= bboxes[:, :2]\n",
    "        bboxes = bboxes.tolist()\n",
    "        labels = targets[\"labels\"].tolist()\n",
    "        areas = targets[\"area\"].tolist()\n",
    "        iscrowd = targets[\"iscrowd\"].tolist()\n",
    "        if \"masks\" in targets:\n",
    "            masks = targets[\"masks\"]\n",
    "            # make masks Fortran contiguous for coco_mask\n",
    "            masks = masks.permute(0, 2, 1).contiguous().permute(0, 2, 1)\n",
    "        if \"keypoints\" in targets:\n",
    "            keypoints = targets[\"keypoints\"]\n",
    "            keypoints = keypoints.reshape(keypoints.shape[0], -1).tolist()\n",
    "        num_objs = len(bboxes)\n",
    "        for i in range(num_objs):\n",
    "            ann = {}\n",
    "            ann[\"image_id\"] = image_id\n",
    "            ann[\"bbox\"] = bboxes[i]\n",
    "            ann[\"category_id\"] = labels[i]\n",
    "            categories.add(labels[i])\n",
    "            ann[\"area\"] = areas[i]\n",
    "            ann[\"iscrowd\"] = iscrowd[i]\n",
    "            ann[\"id\"] = ann_id\n",
    "            if \"masks\" in targets:\n",
    "                ann[\"segmentation\"] = coco_mask.encode(masks[i].numpy())\n",
    "            if \"keypoints\" in targets:\n",
    "                ann[\"keypoints\"] = keypoints[i]\n",
    "                ann[\"num_keypoints\"] = sum(k != 0 for k in keypoints[i][2::3])\n",
    "            dataset[\"annotations\"].append(ann)\n",
    "            ann_id += 1\n",
    "    dataset[\"categories\"] = [{\"id\": i} for i in sorted(categories)]\n",
    "    coco_ds.dataset = dataset\n",
    "    coco_ds.createIndex()\n",
    "    return coco_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb8134c-3078-4fe6-820b-a3f18993647c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 3. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661b027c-19e3-47cb-90a9-e5b196c02e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"mmdetection\" not in sys.path:\n",
    "    sys.path.insert(0, \"mmdetection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe21c52-5b0d-4b9f-9c1a-c442cb58ec7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = \"fruit_detection.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db0ebe4-88a5-470d-8237-7406e9fbae5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmcv import Config\n",
    "from mmdet.datasets import build_dataset, build_dataloader\n",
    "from mmdet.models import build_detector\n",
    "\n",
    "cfg = Config.fromfile(config)\n",
    "dataset = build_dataset(cfg.data.train)\n",
    "model = build_detector(cfg.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6ea6feca-37e8-4f9c-804b-12e16e1adcc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "670"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a8d712-60bf-4cc0-a954-ce72530297bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdet.apis import init_detector, inference_detector\n",
    "\n",
    "model = build_detector(cfg.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04d0e20-dbd0-464b-abb7-dc5ad2f83452",
   "metadata": {},
   "source": [
    "## Rough: Train in code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6a218ffa-e346-4743-9e6f-bce07c070f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmcv import Config\n",
    "from mmdet.datasets import build_dataset, build_dataloader\n",
    "from mmdet.models import build_detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "87303267-c8f0-4f39-a2a5-eec22ea8c126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/jupyter/ai-playground/object-detection',\n",
       " '/opt/conda/lib/python37.zip',\n",
       " '/opt/conda/lib/python3.7',\n",
       " '/opt/conda/lib/python3.7/lib-dynload',\n",
       " '',\n",
       " '/opt/conda/lib/python3.7/site-packages',\n",
       " '/opt/conda/lib/python3.7/site-packages/IPython/extensions',\n",
       " '/home/jupyter/.ipython',\n",
       " 'mmdetection']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "if \"mmdetection\" not in sys.path:\n",
    "    sys.path.append(\"mmdetection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e2ab08ff-275c-4c01-a475-8c8bfc972bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = \"fruit_detection.py\"\n",
    "\n",
    "cfg = Config.fromfile(config)\n",
    "\n",
    "args = cfg.data.train.copy()\n",
    "args.pop(\"type\")\n",
    "dataset = MineAppleDataset(**args)\n",
    "# datasets = [build_dataset(cfg.data.train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "049bec5c-1007-4fc1-bc32-8e14dc5a6255",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_detector(cfg.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2c2c842-d879-4076-bdfa-90f011a9d011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single GPU training\n",
    "cfg.gpu_ids = range(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e2c0671-c504-49d9-8efd-9a43935e41b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.distributed as dist\n",
    "from mmdet.apis import init_random_seed, set_random_seed, train_detector\n",
    "from mmdet.utils import (collect_env, get_device, get_root_logger,\n",
    "                         setup_multi_processes, update_data_root)\n",
    "\n",
    "deterministic = False\n",
    "seed = 0\n",
    "\n",
    "cfg.device = get_device()\n",
    "\n",
    "# set random seeds\n",
    "seed = init_random_seed(seed, device=cfg.device)\n",
    "set_random_seed(seed, deterministic=deterministic)\n",
    "cfg.seed = seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bf5acb9-8e21-4f96-b517-084879737ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "distributed = False\n",
    "runner_type = 'EpochBasedRunner' if 'runner' not in cfg else cfg.runner['type']\n",
    "train_dataloader_default_args = dict(\n",
    "    samples_per_gpu=2,\n",
    "    workers_per_gpu=2,\n",
    "    # `num_gpus` will be ignored if distributed\n",
    "    num_gpus=len(cfg[\"gpu_ids\"]),\n",
    "    dist=distributed,\n",
    "    seed=cfg[\"seed\"],\n",
    "    runner_type=runner_type,\n",
    "    persistent_workers=False)\n",
    "\n",
    "train_loader_cfg = {\n",
    "    **train_dataloader_default_args,\n",
    "    **cfg.data.get('train_dataloader', {})\n",
    "}\n",
    "data_loader = build_dataloader(dataset, **train_loader_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5215f7a3-911b-4526-89b7-bf01f96e1cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "from mmdet.apis.train import train_detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d3ceb65-89b4-40c7-8271-a9a70eead709",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_validate = False\n",
    "\n",
    "timestamp = time.strftime('%Y%m%d_%H%M%S', time.localtime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "272b290a-c853-4e3d-80e2-60396e0013e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.work_dir = os.path.join('./work_dirs',\n",
    "                        os.path.splitext(os.path.basename(config))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686a145a-cb7e-45f4-ba69-af03152dc5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_info_dict = collect_env()\n",
    "env_info = '\\n'.join([(f'{k}: {v}') for k, v in env_info_dict.items()])\n",
    "meta = {\n",
    "    \"env_info\": env_info,\n",
    "    \"config\": cfg.pretty_text,\n",
    "    \"seed\": cfg.seed,\n",
    "    \"exp_name\": os.path.basename(config)\n",
    "}\n",
    "\n",
    "train_detector(model, [dataset], cfg, distributed=distributed, validate=(not no_validate), timestamp=timestamp, meta=meta)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-11.m91",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-11:m91"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
